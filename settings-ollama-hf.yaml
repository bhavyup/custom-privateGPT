server:
  env_name: ${APP_ENV:ollama-hf}

llm:
  mode: ollama
  max_new_tokens: 512
  context_window: 3900
  temperature: 0.1

# USE HUGGINGFACE FOR EMBEDDINGS (more stable than Ollama)
embedding:
  mode: huggingface

huggingface:
  embedding_hf_model_name: BAAI/bge-small-en-v1.5

ollama:
  llm_model: llama3.2
  api_base: http://localhost:11434
  keep_alive: 5m
  tfs_z: 1.0
  top_k: 40
  top_p: 0.9
  repeat_last_n: 64
  repeat_penalty: 1.2
  request_timeout: 600.0

vectorstore:
  database: qdrant

qdrant:
  path: local_data/private_gpt/qdrant_hf
